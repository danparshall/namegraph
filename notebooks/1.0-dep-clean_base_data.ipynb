{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean base data\n",
    "\n",
    "This notebook takes the input data file, produces a cleaned version.  One of the biggest challenges is names with spaces, so I attempt to replace the spaces with underscores.  How do I know which names have spaces?  By having cleaned and processed the data through NB 3 already.  After NB 3 I save the results, and then use that file as an input here.  It makes other things much, much easier.\n",
    "\n",
    "I also check for labels/notes that have been put into the fields.  E.g. duplicate records, people who need to provide birth certificates, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "import unidecode\n",
    "from fuzzywuzzy import fuzz    \n",
    "    \n",
    "# enable progress bar on long operations\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = True\n",
    "N_ROWS = None  # 1000000\n",
    "READ_DATE = '20200823'\n",
    "\n",
    "LOC_RAW = \"../data/raw/\"\n",
    "\n",
    "LOC_RAWFILE = LOC_RAW + 'RAW_SAMPLE.tsv'\n",
    "\n",
    "LOC_INTERIM = \"../data/interim/\"\n",
    "\n",
    "TODAY = dt.datetime.now().strftime(\"%Y%m%d\")\n",
    "TODAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load special names data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC_SPECIAL = \"../data/interim/special_names.txt\"\n",
    "\n",
    "specials = set()\n",
    "with open(LOC_SPECIAL) as f:\n",
    "    for line in f:\n",
    "        if line:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # eliminate comments\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            line = line.split('#')[0].strip()\n",
    "            \n",
    "            specials.add(line)\n",
    "len(specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"../data/interim/ALLNAMES_20200824.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in all cases, we look for a word boundary as the first group, then our funky name as the second\n",
    "re_von = re.compile(u\"(^|\\s)(V[AO]N \\w{2,})(\\s|$)\")              # these results are subset of \"re_vande\"\n",
    "re_vande = re.compile(u\"(^|\\s)(V[AO]N DE[RN]? \\w{2,})(\\s|$)\")\n",
    "re_sant = re.compile(u\"(^|\\s)(SANT?A? \\w{2,})(\\s|$)\")            # SAN and SANTA (SANTO doesn't form compounds)\n",
    "re_dela = re.compile(u\"(^|\\s)(DE L[AO]S? ?[AO]? ?\\w{2,})(\\s|$)\")   # these results are subset of \"re_laos\"\n",
    "re_laos = re.compile(u\"(^|\\s)(L[AEO]S? \\w{2,})(\\s|$)\")\n",
    "re_del  = re.compile(u\"(^|\\s)(DEL \\w{2,})(\\s|$)\")\n",
    "re_de   = re.compile(r\"(^|\\s)(DE \\w{2,})(\\s|$)\")\n",
    "\n",
    "\n",
    "def regex_compound_names(nombre):\n",
    "    \"\"\" This is a little slow (~4mins / million rows), but pretty thorough.  \"\"\"\n",
    "    \n",
    "    mdel   = re_del.search(nombre)\n",
    "    msant  = re_sant.search(nombre)\n",
    "    \n",
    "    mlaos  = re_laos.search(nombre)\n",
    "    mdela  = re_dela.search(nombre)\n",
    "    \n",
    "    mvon   = re_von.search(nombre)\n",
    "    mvande = re_vande.search(nombre)\n",
    "    \n",
    "    mde    = re_de.search(nombre)\n",
    "    \n",
    "    poss_funks = set()\n",
    "    \n",
    "    if mdel:\n",
    "        poss_funks.add(mdel.group(2))\n",
    "    if msant:\n",
    "        poss_funks.add(msant.group(2))\n",
    "    if mvon:\n",
    "        # \"VAN DE\" types are a subset of \"VAN\" types\n",
    "        if mvande:\n",
    "            poss_funks.add(mvande.group(2))\n",
    "        else:\n",
    "            poss_funks.add(mvon.group(2))\n",
    "    if mlaos:\n",
    "        # \"DE LA\" type names are a subset of \"LA\" types\n",
    "        if mdela:\n",
    "            poss_funks.add(mdela.group(2))\n",
    "        else:\n",
    "            poss_funks.add(mlaos.group(2))\n",
    "    if mde:\n",
    "        poss_funks.add(mde.group(2))\n",
    "\n",
    "    if poss_funks:\n",
    "        for funk in poss_funks:\n",
    "            compound_names.add(funk)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Reg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_unders(nombre):\n",
    "    # this function adds underscores to compound names; gets run in \"fix_nombre()\"\n",
    "    for d in compound_names:\n",
    "        if d in nombre:\n",
    "            # if we've got a candidate match, confirm with a regex (to be sure there's no end-effects)\n",
    "            m = re.search(\"(^|\\s)(\" + d + \")(\\s|$)\", nombre)\n",
    "            if m:\n",
    "                new = \"_\".join(m.group(2).split())\n",
    "                parts = [x.strip() for x in nombre.split(m.group(2))]\n",
    "                nombre = ' '.join([parts[0], new, parts[1]]).strip()\n",
    "    return nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_star = re.compile(r'^[\\s*+/]+$')\n",
    "re_starplus = re.compile(r'(^[\\s*]+)([\\w\\s]+)')\n",
    "re_oddchars = re.compile(r\"[,'·./+$<>{}()\\[\\]\\\\]+\")   # triggers on one or more of \"·./+$\\(){}[]<>\"\n",
    "re_dash = re.compile(r\"\\w+\\s?-\\s?\\w+\")\n",
    "re_exes = re.compile(r\"^[Xx\\s]+$\")\n",
    "re_irish = re.compile(r\"DE LA O \\w+|.*(^|\\s)(O['\\s]+\\w{2,})(\\s|$)\")\n",
    "re_mac = re.compile(r\".*(^|\\s)(MA?C\\s\\w{2,})\\s\")\n",
    "re_dela_aos = re.compile(r'(^|\\s)(DE LA [AOS]{1})(\\s|$)')\n",
    "re_solo_d = re.compile(r\"(^|\\s)(D['\\s]+\\w{2,})(\\s|$)\")  # ~600\n",
    "re_solo_l = re.compile(r\"(^|\\s)(L['\\s]+\\w{2,})(\\s|$)\")  # ~35\n",
    "re_del_broken = re.compile(r'(^|\\s)(DE L) \\w.*')        # ~20; sometimes \"DE L HERMITE\", others \"D L ANGELES\"\n",
    "# ^^ alternatively, could \"D L ANGELES\" be an abbreviation for \"DE LOS ANGELES\" ?\n",
    "\n",
    "\n",
    "def fix_nombre(nombre):\n",
    "    \n",
    "    # blank/null return empty string\n",
    "    if isinstance(nombre, float):\n",
    "        nombre = \"\"\n",
    "    \n",
    "    # accents, enyes, etc are ALMOST always used.  But better to ditch them\n",
    "    nombre = unidecode.unidecode(nombre)\n",
    "            \n",
    "    # The surnames \"DE LA A\" and \"DE LA O\" exist, and are a plague.  Fix them now\n",
    "    # 2020/09/15... so does \"DE LA S\"\n",
    "    m_dela = re_dela_aos.search(nombre)\n",
    "    if m_dela:\n",
    "        new = '-'.join(m_dela.group(2).split()).strip()\n",
    "        parts = [x.strip() for x in nombre.split(m_dela.group(2))]\n",
    "#        nombre = parts[0] + new + parts[1]\n",
    "        nombre = \" \".join([parts[0], new, parts[1]]).strip()\n",
    "        \n",
    "    ## remove apostrophe/space from irish surnames (e.g O'BRIAN ==> OBRIAN)\n",
    "    ## complicated because \"DE LA O BRIAN\" could be \"O'BRIAN\", so I have to play tricks with the grouping\n",
    "    ## NB - I'm now handling \"DE LA O\" directly, could make this more like the others\n",
    "    m = re_irish.match(nombre)\n",
    "    if m:\n",
    "        g = m.group(2)\n",
    "        if g:\n",
    "            new = \"\".join(g.split(\"'\"))\n",
    "            new = \"\".join(new.split())\n",
    "            parts = [x.strip() for x in nombre.split(g)]\n",
    "            nombre = \" \".join([parts[0], new, parts[1]]).strip()\n",
    "    \n",
    "    # similarly, fix MAC/MC names\n",
    "    mac = re_mac.match(nombre)\n",
    "    if mac:\n",
    "        g = mac.group(2)\n",
    "        if g:\n",
    "            new = \"\".join(g.split())\n",
    "            parts = [x.strip() for x in nombre.split(g)]\n",
    "            nombre = \" \".join([parts[0], new, parts[1]]).strip()\n",
    "        \n",
    "    # plenty of D'ARTAN as well\n",
    "    m_solo_d = re_solo_d.search(nombre)\n",
    "    if m_solo_d:\n",
    "        g = m_solo_d.group(2)\n",
    "        if g:\n",
    "            new = \"\".join(g.split())\n",
    "            parts = [x.strip() for x in nombre.split(g)]\n",
    "            nombre = \" \".join([parts[0], new, parts[1]]).strip()\n",
    "    \n",
    "    # ditch weird characters before proceeding\n",
    "    nombre = ''.join(re_oddchars.split(nombre))\n",
    "    \n",
    "    if re_star.match(nombre):\n",
    "        nombre = \"\"\n",
    "    if re_exes.match(nombre):\n",
    "        nombre = \"\"\n",
    "    if re_starplus.match(nombre):\n",
    "        nombre = \"**\" + re_starplus.match(nombre).group(2) + \"**\"\n",
    "    if \" - \" in nombre:\n",
    "        nombre = \"-\".join(nombre.split(\" - \"))\n",
    "    if \" -\" in nombre:\n",
    "        nombre = \"-\".join(nombre.split(\" -\"))\n",
    "    if \"- \" in nombre:\n",
    "        nombre = \"-\".join(nombre.split(\"- \"))\n",
    "#    if \" DE EL \" in nombre:\n",
    "#        nombre = \" DEL \".join(nombre.split(\" DE EL \" ))\n",
    "    \n",
    "    nombre = sub_unders(nombre)\n",
    "    return nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nan_values = ['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN', '#N/A N/A', '#N/A', 'N/A', 'n/a', # 'NA' is sometimes name\n",
    "              '<NA>', '#NA', 'NULL', 'null', 'NaN', '-NaN', 'nan', '-nan', '']\n",
    "\n",
    "date_cols = ['dt_birth', 'dt_death', 'dt_marriage']\n",
    "\n",
    "dtypes_namedata = {'cedula':str, 'nombre':str, 'nombre_spouse':str, 'orig_cedula':str, \n",
    "                   'nombre_padre':str, 'nombre_madre':str, 'ced_spouse':str, 'ced_padre':str, 'ced_madre':str,\n",
    "                  'is_nat':bool, 'is_nat_padre':bool, 'is_nat_madre':bool,\n",
    "                  }\n",
    "\n",
    "rf = pd.read_csv(LOC_RAWFILE, sep='\\t', encoding='latin',\n",
    "                parse_dates=date_cols, dtype=dtypes_namedata,\n",
    "                 keep_default_na=False, na_values=nan_values,\n",
    "                 nrows=N_ROWS,\n",
    "                )\n",
    "\n",
    "if full_run:\n",
    "\n",
    "    # cleanup names\n",
    "    namecols =  ['nombre', 'nombre_spouse', 'nombre_padre', 'nombre_madre']\n",
    "    for col in namecols:\n",
    "        print(col)\n",
    "        rf[col] = rf[col].map(fix_nombre)\n",
    "\n",
    "    # save cleaned input data\n",
    "    rf.to_csv(LOC_RAW + \"NAMES__c01__\" + TODAY + \".tsv\", sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# replace NaN with empty string\n",
    "text_cols = ['nombre', 'nombre_spouse', 'nombre_padre', 'nombre_madre', 'ced_spouse', 'ced_padre', 'ced_madre']\n",
    "#rf[text_cols] = rf[text_cols].fillna(\"\")\n",
    "\n",
    "print(\"# records loaded :\", len(rf))\n",
    "# 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = rf[rf.duplicated(subset=['nombre','dt_birth'], keep=False)].sort_values(['dt_birth','nombre'])\n",
    "len(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups[(dups.nombre_spouse != \"\") & (dups.gender == '1')][-50:]   # later dups are caught earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dups[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_out = {}\n",
    "\n",
    "nulls = {np.nan, pd.NaT}\n",
    "\n",
    "for col in rec1.index:\n",
    "    r1 = rec1[col]\n",
    "    r2 = rec2[col]\n",
    "    \n",
    "    if r1 == r2:\n",
    "        rec_out[col] = r1\n",
    "    elif r1 in nulls:\n",
    "        rec_out[col] = r2\n",
    "    elif r2 in nulls:\n",
    "        rec_out[col] = r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = rf[(rf.orig_cedula != rf.cedula)]\n",
    "len(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old[old.apply(lambda row: (row.cedula[1:] != row.orig_cedula), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if full_run:\n",
    "    bigamos = rf[ rf.nombre.map(lambda x: \"BIGAMO\" in x)\n",
    "                  | rf.nombre_padre.map(lambda x: \"BIGAMO\" in x)\n",
    "                  | rf.nombre_madre.map(lambda x: \"BIGAMO\" in x)\n",
    "                ]\n",
    "    bigamos.to_csv(LOC_RAW + \"BIGAMOS_\" + TODAY + \".tsv\", sep='\\t')\n",
    "else:\n",
    "    bigamos = pd.read_csv(LOC_RAW + \"BIGAMOS_\" + READ_DATE + \".tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "print(\"# bigamists :\", len(bigamos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "re_pago = re.compile(r\"PAG[AO]? MULT\")\n",
    "\n",
    "if full_run:\n",
    "    pagos = rf[ rf.nombre.map(lambda x: True if re_pago.search(x) else False)\n",
    "                | rf.nombre_padre.map(lambda x: True if re_pago.search(x) else False)\n",
    "                | rf.nombre_madre.map(lambda x: True if re_pago.search(x) else False)\n",
    "                ]\n",
    "    pagos.to_csv(LOC_RAW + \"PAGOS_\" + TODAY + \".tsv\", sep='\\t')\n",
    "else:\n",
    "    pagos = pd.read_csv(LOC_RAW + \"PAGOS_\" + READ_DATE + \".tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "print(\"# pagos :\", len(pagos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "re_nacimento = re.compile(r\"(^|\\s|\\*)(NAC|NCM)[\\w\\s]*\\d{2,4}\")\n",
    "\n",
    "if full_run:\n",
    "    nacs = rf[ rf.nombre_padre.map(lambda x: True if re_nacimento.search(x) else False)\n",
    "              | rf.nombre_madre.map(lambda x: True if re_nacimento.search(x) else False)\n",
    "              | rf.nombre_spouse.map(lambda x: True if re_nacimento.search(x) else False)\n",
    "              | rf.nombre.map(lambda x: True if re_nacimento.search(x) else False)\n",
    "            ]\n",
    "    nacs.to_csv(LOC_RAW + \"NACIMENTOS_\" + TODAY + \".tsv\", sep='\\t', index=False)\n",
    "else:\n",
    "    nacs = pd.read_csv(LOC_RAW + \"NACIMENTOS_\" + READ_DATE + \".tsv\", sep='\\t', dtype=str)\n",
    "    \n",
    "print(\"# NACIMENTOS :\", len(nacs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# \"CED 2 VECES\", \"CED DOS VEC\", \"CEDL2VECES\", \"DOS CED\", \"2 CEDULAS\"\n",
    "re_cedula = re.compile(r\"(DOB|DUP|DOS|2)\\w{0,}\\s?CE?DU?L?A?\")\n",
    "\n",
    "if full_run:\n",
    "    dobles = rf[ rf.nombre_padre.map(lambda x: True if re_cedula.search(x) else False)\n",
    "                | rf.nombre_madre.map(lambda x: True if re_cedula.search(x) else False)\n",
    "                | rf.nombre.map(lambda x: True if re_cedula.search(x) else False)\n",
    "                | rf.nombre_spouse.map(lambda x: True if re_cedula.search(x) else False)\n",
    "              ]\n",
    "    dobles.to_csv(LOC_RAW + \"DOBLES_\" + TODAY + \".tsv\", sep='\\t', index=False)\n",
    "else:\n",
    "    dobles = pd.read_csv(LOC_RAW + \"DOBLES_\" + READ_DATE + \".tsv\", sep='\\t', dtype=str)\n",
    "print(\"# doble-cedula recs \", len(dobles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# \"PEDIR PARTIDA NACIMIENTO\" and abbrev (e.g. \"PP NAC\", \"P P NACI\")\n",
    "# WARNING! has some false positives (e.g. \"PULLOPAXI NACIMBA ROBERTH GABRIEL\")\n",
    "#re_ppnac = re.compile(r\"P\\w{0,}\\s?P\\w{0,}\\s[DE]{0,2}\\s?NAC\\w*\")\n",
    "\n",
    "# improved, shouldn't have false positives\n",
    "re_ppnac = re.compile(r\"P(P|\\w{0,}\\sP\\w{0,})\\s[DE]{0,2}\\s?(NAC|NCM)\\w*\")\n",
    "\n",
    "if full_run:\n",
    "    ppnaci = rf[ rf.nombre_padre.map(lambda x: True if re_ppnac.search(x) else False)\n",
    "                 | rf.nombre_madre.map(lambda x: True if re_ppnac.search(x) else False)\n",
    "                 | rf.nombre.map(lambda x: True if re_ppnac.search(x) else False)\n",
    "                 | rf.nombre_spouse.map(lambda x: True if re_ppnac.search(x) else False)\n",
    "           ]\n",
    "    ppnaci.to_csv(LOC_RAW + \"PPNAXI_\" + TODAY + \".tsv\", sep=\"\\t\", index=False)\n",
    "else:\n",
    "    ppnaci = pd.read_csv(LOC_RAW + \"PPNAXI_\" + READ_DATE + \".tsv\", sep='\\t', dtype=str)\n",
    "\n",
    "print(\"# PPNACI \", len(ppnaci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ced_map = {'0':0, '1':2, '2':4, '3':6, '4':8, '5':1, '6':3, '7':5, '8':7, '9':9}\n",
    "def isvalid_cedula(ced):\n",
    "\n",
    "    try:\n",
    "        if len(ced) != 10:\n",
    "            print(\"CED NOT 10 :\", ced)\n",
    "            return False\n",
    "    except TypeError:\n",
    "        print(\"NONETYPE :\", ced)\n",
    "    \n",
    "    oddsum = sum([int(x) for x in ced[1] + ced[3] + ced[5] + ced[7]])\n",
    "    evensum = sum([ced_map[x] for x in ced[0] + ced[2] + ced[4] + ced[6] + ced[8]])\n",
    "    \n",
    "    # last digit is a checksum\n",
    "    is_valid = str(np.mod(10 - np.mod(oddsum + evensum, 10), 10)) == ced[9]\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(\"INVALID :\", ced)\n",
    "    return is_valid\n",
    "\n",
    "if True:\n",
    "    ceds_bad = {'ISOLINA', '94268547', ' ARELLANO VIOLETA'}   # only 3 errors out of 20M, not bad!\n",
    "\n",
    "elif full_run:\n",
    "#    bad_ced_recs = rf[~rf.cedula.map(isvalid_cedula)]\n",
    "    bad_ced_recs.to_csv(LOC_RAW + \"BAD_CEDULA_RECS_\" + TODAY + \".tsv\", sep='\\t', index=False, dtype=str)\n",
    "    ceds_bad = set(bad_ced_recs.cedula)\n",
    "    # ~3 mins\n",
    "    \n",
    "\n",
    "rf = rf[~rf.cedula.isin(ceds_bad)]\n",
    "print(\"# recs with valid cedula :\", len(rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "re_digits = re.compile(r\"[\\w\\s]+\\d+\")\n",
    "\n",
    "if False: #full_run:\n",
    "    digits = rf[  rf.nombre_padre.map(lambda x: True if re_digits.search(x) else False)\n",
    "                | rf.nombre_madre.map(lambda x: True if re_digits.search(x) else False)\n",
    "                | rf.nombre_spouse.map(lambda x: True if re_digits.search(x) else False)\n",
    "                | rf.nombre.map(lambda x: True if re_digits.search(x) else False)\n",
    "                ]\n",
    "    digits.to_csv(LOC_RAW + \"DIGITS_\" + TODAY + \".tsv\", sep='\\t', index=False)\n",
    "elif True:\n",
    "    digits = pd.read_csv(LOC_RAW + \"DIGITS_20200822.tsv\", sep='\\t', dtype=str)\n",
    "else:\n",
    "    digits = pd.read_csv(LOC_RAW + \"DIGITS_\" + READ_DATE + \".tsv\", sep='\\t', dtype=str)\n",
    "    \n",
    "print(\"# recs with digits :\", len(digits))\n",
    "# ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all \"bad\" records from reg frame, then save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badlist = [set(bigamos.cedula), set(dobles.cedula), set(pagos.cedula), set(nacs.cedula),\n",
    "             set(ppnaci.cedula), set(digits.cedula), ceds_bad]\n",
    "\n",
    "tot = 0\n",
    "for x in badlist:\n",
    "    tot += len(x)\n",
    "print(tot)  # 10763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceds_junk = set()\n",
    "\n",
    "#[ceds_junk.add(y) for y in x for x in badlist]\n",
    "\n",
    "for x in badlist:\n",
    "    for y in x:\n",
    "        ceds_junk.add(y)\n",
    "len(ceds_junk)  # 8541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = rf[~rf.cedula.isin(ceds_junk)]\n",
    "\n",
    "print(\"# decent recs :\", len(rf))\n",
    "rf.reset_index(inplace=True, drop=True)\n",
    "rf.to_csv(LOC_RAW + \"NAMES__c01__\" + TODAY + \".tsv\", sep='\\t', index=False)\n",
    "\n",
    "# 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
